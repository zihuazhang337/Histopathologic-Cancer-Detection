{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d731e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet50, resnet18\n",
    "\n",
    "from cutmix.cutmix import CutMix\n",
    "from cutmix.utils import CutMixCrossEntropyLoss\n",
    "from d2l import torch as d2l\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778115d",
   "metadata": {},
   "source": [
    "## Cancer detection\n",
    "This project Will use histopathologic cancer dataset from Kaggle, and detect which image has the cancer\n",
    "\n",
    "Let's get some idea of our data. First by looking at the image and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24182ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "train_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76490b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       f38a6374c348f90b587e046aac6079959adf3835\n",
      "label                                           0\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.TiffImagePlugin.TiffImageFile image mode=RGB size=96x96 at 0x24B6E218EE0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'train/' + train_labels.loc[0]['id'] + '.tif'\n",
    "print(train_labels.loc[0])\n",
    "Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a14535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# let's see how many target label we have\n",
    "train_labels = sorted(list(set(train_labels['label'])))\n",
    "n_classes = len(train_labels)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2acc9",
   "metadata": {},
   "source": [
    "#### we can see that we only have two classes, yes or no. So we will use sigmoid activation function instead of SoftMax function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ef661",
   "metadata": {},
   "source": [
    "### Preprocessing image \n",
    "In order to have a consist input, we will preprocessing our image, resize, and normalize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c711bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43e808",
   "metadata": {},
   "source": [
    "## dataset class\n",
    "In order to use the neural network, we have to marge the image with the label. So we create the my_dataset class, that will return the image with its label. Also, using this class, we can easily modify our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94d4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the preprocessing function, in our case we  only resize the image and do the normalization\n",
    "# we want the do more preprocessing easily by changing the function below\n",
    "\n",
    "\n",
    "#my dataset class\n",
    "class my_dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = pre_train_transform, prefix = ''):\n",
    "        super(my_dataset, self).__init__()\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.prefix = prefix\n",
    "        self.img = self.data['id']\n",
    "        self.label = self.data['label']\n",
    "        self.transform = transform\n",
    "        self.length = len(self.label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.prefix + self.img[idx] + '.tif'\n",
    "        img = Image.open(path)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        label = self.label[idx]\n",
    "        number_label = label\n",
    "\n",
    "        return img, number_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7185aa9",
   "metadata": {},
   "source": [
    "### Setup the network\n",
    "We will setup our network here. In our case, we will use ResNet18 and ResNet50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0ef2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnest18_model(num_classes, pretrained = True, frozen_feature = False):\n",
    "    model = resnet18(pretrained = pretrained)\n",
    "    \n",
    "    if frozen_feature:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    fc_in_feature = model.fc.in_features\n",
    "    #model.fc = nn.Sequential(nn.Linear(fc_in_feature, num_classes))\n",
    "    model.fc = nn.Sequential(nn.Linear(fc_in_feature, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "    return model\n",
    "\n",
    "def resnest50_model(num_classes, pretrained = True, frozen_feature = False):\n",
    "    model = resnet50(pretrained = pretrained)\n",
    "    \n",
    "    if frozen_feature:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    fc_in_feature = model.fc.in_features\n",
    "    #model.fc = nn.Sequential(nn.Linear(fc_in_feature, num_classes))\n",
    "    model.fc = nn.Sequential(nn.Linear(fc_in_feature, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5a601",
   "metadata": {},
   "source": [
    "### CPU or GPU\n",
    "we are using pytorch, and we can decide runing this program on cpu or gpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f554eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63957d42",
   "metadata": {},
   "source": [
    "### Training \n",
    "now, we will train the model, here is the training and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c08d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, loss_func, optimizer, scheduler = None):\n",
    "    best_loss = 100\n",
    "    for i in range(epochs):\n",
    "        train_losses = []\n",
    "        \n",
    "        model.train()\n",
    "        print(f'')\n",
    "        for img, label in tqdm(train_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device).to(torch.float32)\n",
    "            \n",
    "            pred = model(img).ravel().to(torch.float32)\n",
    "            loss = loss_func(pred, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        loss = np.sum(train_losses) / len(train_losses)\n",
    "        print(f'epochs {i+1} - loss {loss} ')\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            torch.save(model.state_dict(), f'./model_auto_save.pth')\n",
    "            best_loss = loss\n",
    "    \n",
    "def train_val(train_loader, valid_loader = None):\n",
    "    model = resnest18_model(2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)#T_max = 10\n",
    "    \n",
    "    train(model, train_loader, epochs, loss_func, optimizer, scheduler)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./model_resnet18.pth')\n",
    "    print('--finish saving!--')\n",
    "    \n",
    "    model.eval()\n",
    "    metric_valid = d2l.Accumulator(3)\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(valid_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            pred = model(img)\n",
    "            loss = loss_func(pred, label)\n",
    "            acc = (pred.argmax(dim=-1) == label.to(device)).float().mean()\n",
    "            metric_valid.add(loss * img.shape[0], d2l.accuracy(pred, label), img.shape[0])\n",
    "            \n",
    "    test_ls, test_acc   = metric_valid[0]/metric_valid[2], metric_valid[1]/metric_valid[2]\n",
    "    print(f'validtion loss {test_ls:.6f}, acc {test_acc:.6f}')\n",
    "    \n",
    "def train_test(train_loader, test_loader, transform):\n",
    "    model = resnest18_model(2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)#T_max = 10\n",
    "    \n",
    "    train(model, train_loader, epochs, loss_func, optimizer, scheduler)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./model_resnet18.pth')\n",
    "    print('--finish saving!--')\n",
    "    \n",
    "    test_prediction = []\n",
    "    model.eval()\n",
    "    metric_valid = d2l.Accumulator(3)\n",
    "    with torch.no_grad():\n",
    "        for img_name in test_loader['id']:\n",
    "            path = 'test/' + img_name + '.tif'\n",
    "            img = Image.open(path)\n",
    "            img = transform(img)            \n",
    "            img = img.to(device)\n",
    "            \n",
    "            pred = model(img.unsqueeze(0))\n",
    "            res = 0 if pred < 0.5 else 1\n",
    "            test_prediction.append({'id':img_name, 'label':res})\n",
    "    \n",
    "    test_pd = pd.DataFrame(test_prediction)\n",
    "    test_pd.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182edaec",
   "metadata": {},
   "source": [
    "### Train and validation\n",
    "before we train our model, we need to select our hyperparameters and models structure. We can use kfold validation to find which models or hyperparameters are the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b32320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor train_ids,valid_ids in kfold.split(train_dataset):\\n    break\\ntrain_sample = torch.utils.data.SubsetRandomSampler(train_ids)\\nvalid_sample = torch.utils.data.SubsetRandomSampler(valid_ids)\\ntrain_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sample)\\nvalid_loader = DataLoader(train_dataset, batch_size=32, sampler=valid_sample)\\n    \\ntrain_val(train_loader, valid_loader)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "#loss_func = nn.CrossEntropyLoss()  \n",
    "loss_func = nn.BCELoss()\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "train_dataset = my_dataset('train_labels.csv', pre_train_transform, 'train/')\n",
    "\n",
    "for train_ids,valid_ids in kfold.split(train_dataset):\n",
    "    break\n",
    "train_sample = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "valid_sample = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sample)\n",
    "valid_loader = DataLoader(train_dataset, batch_size=32, sampler=valid_sample)\n",
    "    \n",
    "train_val(train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df7d7b",
   "metadata": {},
   "source": [
    "### Final training and testing\n",
    "After we choose the model and hyperparameters, we will train our model with all the training dataset, and predict the testing image. And we will store the prediction in 'submission.csv' file \n",
    "\n",
    "In our case we will use resnet18, for it is smaller and easier to train. Our training dataset is large, if we use resnet50, it will take more than one hour to train ten epochs. For efficiency we will use resnet18. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7b18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:30<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 - loss 0.18453521039886828 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:02<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 - loss 0.10056062949973864 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [05:31<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 - loss 0.05700355861537468 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [05:24<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 - loss 0.034056218072787754 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [05:18<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 - loss 0.020203690250739578 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:04<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 6 - loss 0.011532518366788437 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:39<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 7 - loss 0.006509412476919419 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:44<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 8 - loss 0.0025827572762777695 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:16<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 9 - loss 0.0007580532260118858 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6876/6876 [06:05<00:00, 18.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 10 - loss 0.0001783413139660684 \n",
      "--finish saving!--\n"
     ]
    }
   ],
   "source": [
    "train_data = DataLoader(train_dataset, batch_size=32)\n",
    "test_csv = pd.read_csv('sample_submission.csv')\n",
    "train_test(train_data, test_csv, pre_train_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
